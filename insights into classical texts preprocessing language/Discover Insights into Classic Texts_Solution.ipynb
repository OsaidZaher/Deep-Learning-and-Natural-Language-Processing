{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discover Insights into Classic Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6abbc8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'import_ipynb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pos_tag, RegexpParser\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimport_ipynb\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtokenize_words\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_sentence_tokenize\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchunk_counters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m np_chunk_counter, vp_chunk_counter\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'import_ipynb'"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag, RegexpParser\n",
    "import import_ipynb\n",
    "from tokenize_words import word_sentence_tokenize\n",
    "from chunk_counters import np_chunk_counter, vp_chunk_counter\n",
    "\n",
    "# import text of choice here\n",
    "text = open(\"dorian_gray.txt\",encoding='utf-8').read().lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb43dd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenized_text = word_sentence_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609552a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_word_tokenized_sentence = word_tokenized_text[100]\n",
    "print(single_word_tokenized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1966a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tagged_text = list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0f614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word_tokenized_sentence in word_tokenized_text:\n",
    "    pos_tagged_text.append(pos_tag(word_tokenized_sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e03c59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_pos_sentence = pos_tagged_text[100]\n",
    "print(single_pos_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175a933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noun phrase chunk grammar here\n",
    "np_chunk_grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57d628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noun phrase RegexpParser object here\n",
    "np_chunk_parser = RegexpParser(np_chunk_grammar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddfa3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verb phrase chunk grammar here\n",
    "vp_chunk_grammar = \"VP: {<DT>?<JJ>*<NN><VB.*><RB.?>?}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1909350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_chunk_parser = RegexpParser(vp_chunk_grammar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7675c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_chunked_text = list()\n",
    "vp_chunked_text = list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d1bc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop through each pos-tagged sentence here\n",
    "for pos_tagged_sentence in pos_tagged_text:\n",
    "    np_chunked_text.append(np_chunk_parser.parse(pos_tagged_sentence))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2673eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop through each pos-tagged sentence here\n",
    "for pos_tagged_sentence in pos_tagged_text:\n",
    "    vp_chunked_text.append(vp_chunk_parser.parse(pos_tagged_sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eba3e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#most common NP-chunks here\n",
    "most_common_np_chunks = np_chunk_counter(np_chunked_text)\n",
    "print(most_common_np_chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a977a6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#most common VP-chunks here\n",
    "most_common_vp_chunks = vp_chunk_counter(vp_chunked_text)\n",
    "print(most_common_vp_chunks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
